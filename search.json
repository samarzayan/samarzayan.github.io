[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "üëã I am Samar, an aspiring data scientist.\nüè´ I have a background in education- I taught Math to high school kids and worked in various domains of the education sectors ranging from schools, NGOs and ed-tech platform doing all sorts of things beyond teaching.\nü§ñ I am looking forward to transition into Data Science. I love the fast.ai course and am amazed by the powerful things it can do. I want to give it a shot and see where it takes me. I wish to build cool AI systems that can do wonderful stuff. That would be my dream job üòç!\n‚ù§Ô∏è I have a wide range of interests ‚Äì education, history, art, movies, books, music, philosophy, theology, and so on!"
  },
  {
    "objectID": "lesson_01.html#introduction",
    "href": "lesson_01.html#introduction",
    "title": "Lesson 1",
    "section": "Introduction",
    "text": "Introduction\nWelcome to Practical Deep Learning For Coders!\nThis is the fifth version of the course.\nIt‚Äôs the first new one that has been done in 2 years since the previous version in 2020 and a lot of cool new things have come up along the way to cover.\n\n\n\nfast.ai 2022"
  },
  {
    "objectID": "lesson_01.html#a-big-jump-since-2015",
    "href": "lesson_01.html#a-big-jump-since-2015",
    "title": "Lesson 1",
    "section": "A Big Jump Since 2015",
    "text": "A Big Jump Since 2015\nIt is amazing how much things have changed.\nBelow is an xkcd (highly popular among most coders and alike) comic from the end of 2015 which depicts the situation back then.\n\n\n\nAn xkcd joke\n\n\nIt can be hard to tell what‚Äôs easy and what‚Äôs impossible in computing.\nIn 2015 it was nearly impossible to create a code that can check if an image is of a bird or not! So impossible that it became the idea of a joke.\nNow in 2022, we can pull it off for free in under 2 minutes."
  },
  {
    "objectID": "lesson_01.html#is-it-a-bird",
    "href": "lesson_01.html#is-it-a-bird",
    "title": "Lesson 1",
    "section": "Is It A Bird?",
    "text": "Is It A Bird?\nThe following Python code does it for us.\n\n\n\n\n\n\nNote\n\n\n\nBelow we run the code very quickly without discussing the nitty-gritty details of the code. We shall come back to it later as we go along.\n\n\n\n!pip install -Uqq fastbook duckduckgo_search\n\n     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 719 kB 15.9 MB/s \n     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5.3 MB 64.1 MB/s \n     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1.3 MB 54.5 MB/s \n     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 441 kB 73.1 MB/s \n     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1.6 MB 55.1 MB/s \n     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 62 kB 1.6 MB/s \n     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 96 kB 7.3 MB/s \n     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 212 kB 62.9 MB/s \n     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 115 kB 73.9 MB/s \n     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 163 kB 77.0 MB/s \n     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 127 kB 74.0 MB/s \n     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 115 kB 76.5 MB/s \n     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7.6 MB 67.3 MB/s \nERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nflask 1.1.4 requires click<8.0,>=5.1, but you have click 8.1.3 which is incompatible.\n\n\nWhenever using a cloud platform like Colab or JNs in Kaggle, it is a good practice to have this cell at the top. Running the above cell makes sure that the most recent version of any library/software is used. Older versions can run into some problems of not running smoothly and cause trivial errors.\nMore info on pip and -Uqq here.\n\nfrom fastbook import *\n\nWe import all the libraries from fastbook using import.\n\nurls = search_images_ddg('bird photos', max_images=1)\nlen(urls), urls[0]\n\n(1,\n 'http://www.saga.co.uk/contentlibrary/saga/publishing/verticals/home-and-garden/gardening/garden-wildlife/galleries/exotic-birds/hoopoe.jpg')\n\n\nHere we are searching in DuckDuckGo for images of birds and grabbing one of them. The URLs are stored in the variable urls.\nThe number of URLs(which is just 1) and the URL of the first image that we grabbed is outputted.\n\ndest = Path('bird.jpg')\nif not dest.exists(): download_url(urls[0], dest, show_progress = False)\n\n\nim = Image.open(dest)\nim.to_thumb(256, 256)\n\n\n\n\nWe download the image.\nSo, the above script is something that can download images of birds (or anything for that matter) from the internet.\nOur goal is to build a system that can recognize images that are birds or not birds. Computers or models need numbers as inputs to work with. Luckily images are indeed made of numbers.\nPixSpy is an online viewer which helps us see these numbers in an image.\nWhat we recognize as a bird photo is basically a set of pixels with RGB values.\n\nsearches = 'forest','bird'\npath = Path('bird_or_not')\n\nif not path.exists():\n    for o in searches:\n        dest = (path/o)\n        dest.mkdir(exist_ok=True, parents = True)\n        results = search_images_ddg(f'{o} photo')\n        download_images(dest, urls=results[:200])\n        resize_images(dest, max_size=400, dest=dest)\n\nTo train our model, we need images of birds and ‚Äúnon-birds‚Äù, but DuckDuckGo or Google doesn‚Äôt show images of ‚Äúnon-birds‚Äù. So, we went with something like images of forests.\nIn the searches, we went and searched for forest images and bird images, and then downloaded and resized them, about 200 of them each.\nWe are resizing it to small pixels because computers take a large amount of time to just open an image that is larger in size.\n\nfailed = verify_images(get_image_files(path))\nfailed.map(Path.unlink);\n\nWhen we download images we often get a few broken ones.\nA model does not work successfully with broken images.\nThe above piece of code finds and veriefies these broken images and unlinks them.\n\ndls = DataBlock(\n    blocks=(ImageBlock, CategoryBlock), \n    get_items=get_image_files, \n    splitter=RandomSplitter(valid_pct=0.2, seed=42),\n    get_y=parent_label,\n    item_tfms=[Resize(192, method='squish')]\n).dataloaders(path, bs=32)\n\ndls.show_batch(max_n=6)\n\n\n\n\nNow, we create what is called a data block.\nData block gives fast.ai library all the information of an image that it needs to create a computer vision model. It gets all the image files that we downloaded and shows us some, let us say 6. We can easily check the data with this.\nSo now we have downloaded 200 images of birds and forests each and have checked them.\n\nlearn = cnn_learner(dls, resnet18, metrics=error_rate)\nlearn.fine_tune(3)\n\n/usr/local/lib/python3.7/dist-packages/fastai/vision/learner.py:284: UserWarning: `cnn_learner` has been renamed to `vision_learner` -- please update your code\n  warn(\"`cnn_learner` has been renamed to `vision_learner` -- please update your code\")\n/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and will be removed in 0.15, \"\n/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\nDownloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n      epoch\n      train_loss\n      valid_loss\n      error_rate\n      time\n    \n  \n  \n    \n      0\n      0.399772\n      0.099666\n      0.026316\n      00:09\n    \n  \n\n\n\n\n\n\n\n\n\n  \n    \n      epoch\n      train_loss\n      valid_loss\n      error_rate\n      time\n    \n  \n  \n    \n      0\n      0.040566\n      0.008731\n      0.000000\n      00:02\n    \n    \n      1\n      0.028078\n      0.019985\n      0.013158\n      00:02\n    \n    \n      2\n      0.025392\n      0.014752\n      0.013158\n      00:02\n    \n  \n\n\n\nHere, the model learns it. This now runs through every photo from the 400 photos and learns about how a bird or a forest looks like.\nOverall it took under 30 s which was enough to finish doing what we saw in the comic.\n\nis_bird,_,probs = learn.predict(PILImage.create('bird.jpg'))\nprint(f\"This is a: {is_bird}.\")\nprint(f\"Probability it's a bird: {probs[0]:.4f}\")\n\n\n\n\n\n\n\n\nThis is a: bird.\nProbability it's a bird: 0.9999\n\n\nBy passing in our own image, we can check if an image is a bird or not with the probability rounded to the nearest to 4 decimal places. Here we have passed the first image of bird we downloaded at the beginning.\nHence, something extraordinary has happened since 2015, something which was considered nearly impossible. What was once a joke, can now be done on our laptop in under 2 minutes."
  },
  {
    "objectID": "lesson_01.html#key-takeaway-from-the-model-we-ran",
    "href": "lesson_01.html#key-takeaway-from-the-model-we-ran",
    "title": "Lesson 1",
    "section": "Key Takeaway From The Model We Ran",
    "text": "Key Takeaway From The Model We Ran\nClearly, creating real-world deep learning working codes does not require:\n\nMuch Code\nMuch Math\nMuch Time\nMuch Data\nExpensive Computers\n\nHence, doing DL is pretty much accessible to everyone."
  },
  {
    "objectID": "lesson_01.html#deep-learning-the-current-world-around-us",
    "href": "lesson_01.html#deep-learning-the-current-world-around-us",
    "title": "Lesson 1",
    "section": "Deep Learning & The Current World Around Us",
    "text": "Deep Learning & The Current World Around Us\nDL is evolving rapidly, thereby giving rise to various new stuff. Following are some recent developments that came about a few weeks before the start of this course.\n\nDeep Learning & Art\n\nDALL.E 2, is an AI that can create real artistic images based on the descriptions we give it.  \nMidjourney, is another similar platform. \nSelf motivated artists use DL to create their own art working on a project for months. \n\nMany fast.ai alums having a background in art have went on to create wonderful arts using DL.\n\n\nDeep Learing & Language\n\nPathways Language Model (PaLM) from Google can take an English text/question as an input and return its output an answer with the explanation or ‚Äúthinking‚Äù. The diversity is vast ranging from Math problems to explaining jokes and beyond. \n\nIn short, DL is doing a lot that we would have considered impossible otherwise."
  },
  {
    "objectID": "lesson_01.html#importance-of-ethics",
    "href": "lesson_01.html#importance-of-ethics",
    "title": "Lesson 1",
    "section": "Importance Of Ethics",
    "text": "Importance Of Ethics\nAn important aspect to keep in consideration when venturing into solving and doing these cool things is Ethics. This will be touched upon in the course, but there is a full ethics course called Practical Data Ethics taught by Dr.¬†Rachel Thomas, the co-founder of fast.ai that covers things in detail."
  },
  {
    "objectID": "lesson_01.html#jeremys-explorations-in-education",
    "href": "lesson_01.html#jeremys-explorations-in-education",
    "title": "Lesson 1",
    "section": "Jeremy‚Äôs Explorations In Education",
    "text": "Jeremy‚Äôs Explorations In Education\nApart from being an AI Researcher, Jeremy is a homeschooling primary school teacher. This has led him to study education and bring the best education practices into his classrooms."
  },
  {
    "objectID": "lesson_01.html#coloured-cups",
    "href": "lesson_01.html#coloured-cups",
    "title": "Lesson 1",
    "section": "Coloured Cups",
    "text": "Coloured Cups\nOne of these practices is the Coloured Cups practice taken from an educator Dylan Wiliam which is an effective way for a teacher to get an idea of the classroom‚Äôs understanding of the lesson or a topic as it is being taught.\nThe idea is simple! All the students in the classrooms have 3 cups, a green cup, a yellow cup, and a red cup each reflecting various levels of understanding. Green means the student is understanding well, yellow means s/he is not quite sure what is going on, and red means the student has no idea of what is going on. As the lesson is being taught, the students put a cup on their desks and the teacher can see the classroom to get a sense of how the students are following along.\nFor this course, a virtual setup was made and Jeremy could see it from his end on the teacher version.\nThe above site was made by Radek one evening, one of the top Fast.ai alums and TA for the course. More about him covered in Lesson 0.\n\n\n\nfast.ai version of the ‚ÄúColored Cups‚Äù\n\n\n\nTakeaway\nAs a learner, it is quite helpful to be self-aware of our situation. Hence, when taking the course independently, we can constantly ask ourselves how we are on the level of understanding.\nWhen we are at red the level, it is better to approach the forums and ask questions."
  },
  {
    "objectID": "lesson_01.html#a-very-different-approach-to-doing-fast.ai",
    "href": "lesson_01.html#a-very-different-approach-to-doing-fast.ai",
    "title": "Lesson 1",
    "section": "A Very Different Approach To Doing fast.ai",
    "text": "A Very Different Approach To Doing fast.ai\nWe began this course, by jumping right in by running a model. We did not do an in-depth review of Linear Algebra and Calculus.\nThis way of teaching is influenced by Jeremy‚Äôs two of the favourite educators Dylan Wiliam and Paul Lockhart (and many others), who claim that learning with a context at hand makes it much better for the learner to learn.\n\n\n\nEducation/learning resources\n\n\nThe way we learn math at school in a very dull way is first we learn counting, then adding, then decimals, blah blah blah and 15 years later in grad-school we do the actual cool stuff. This is not the way most people learn effectively.\nThe best way to learn is the way we learn sports. We jump right in on the ground and start playing it instead of sitting in a classroom and studying the physics of the sport.\nDo not worry though, we will go in-depth as we progress as the most sophisticated technically detailed class out there. but first, we focus on building and deploying models. we will learn why and how things work later.\nFolks having a technical background might find it difficult to cope with this style.\nThere will be a lot of tricks and cool learning philosophies that will be embedded and scattered throughout this course, sometimes it will be called out by Jeremy sometimes it won‚Äôt but it will be there."
  },
  {
    "objectID": "lesson_01.html#the-book",
    "href": "lesson_01.html#the-book",
    "title": "Lesson 1",
    "section": "The Book",
    "text": "The Book\nThe course is closely based on the textbook written by Jeremy and Sylvain titled Deep Learning for Coders with fastai and PyTorch: AI Applications Without a PhD.\nThe course will not use any materials from the book directly which might come as a surprise as we read, but the reason is that important educational research literature claims that learners learn best when the same thing is expressed in multiple different ways. The book will have the same information presented in a different way.\nOne of the bits of the HW is to read the corresponding chapter of the book.\nA lot of people love the book\n\n\n\nfast.ai textbook"
  },
  {
    "objectID": "lesson_01.html#about-jeremy",
    "href": "lesson_01.html#about-jeremy",
    "title": "Lesson 1",
    "section": "About Jeremy",
    "text": "About Jeremy\nSpent 30 years of his life working around DL & ML.\nHe built multiple companies centered around DL.\nHe is the highest-ranked competitor on Kaggle.\n\n\n\nAbout Jeremy\n\n\nOne of his companies Enlitic was the first company to specialize in DL for medicine.\nIt made it to the top 20 smartest companies in 2016 by MIT Technology Review.\n\n\n\nEnlitic featured in MIT Tech Review\n\n\nHe started fast.ai along with Rachel Thomas a few years ago and it had a big impact in the world already.\n\n\n\nfast.ai media coverage\n\n\nApart from the company‚Äôs success, along with the students they have had global recognitions for multiple projects and competitions.\nOne of them is their win in the DAWNBench competition, in which they demonstrated how they can train big neural networks, faster and cheaper than anybody in the world. That was a very big step in 2018.\n\n\n\nfast.ai creating a record breaking model\n\n\nSooner the work made a big difference. Google and NVIDIA started using their approaches and methods to optimise many of their projects.\n\n\n\nfast.ai used at NVIDIA\n\n\nHe is the inventor of the ULMFIT algorithm, which according to the  was one of the two key foundations behind the modern NLP revolution.\nInterestingly, the ULMFIT model did not appear in the journal first, but in the 2016 fast.ai course in lesson 4 and was later developed into a paper.\n\n\n\nJeremy featured in an NLP textbook\n\n\nSince, the first year of teaching the course it got noticed by HBR\n\n\n\nfast.ai in HBR\n\n\nAnd the course is loved by most of them on YouTube.\n\n\n\nLecture YouTube analytics\n\n\nMany alumni went on to do great things."
  },
  {
    "objectID": "lesson_01.html#importance-of-the-course-in-the-industry",
    "href": "lesson_01.html#importance-of-the-course-in-the-industry",
    "title": "Lesson 1",
    "section": "Importance Of The Course In The Industry",
    "text": "Importance Of The Course In The Industry\nThe course is widely used in industry and research with a lot of success.\nAndrej Karpathy said that everybody who joins the Tesla AI team are required to do this course.\nIn OpenAI all the residents joining are required to do this course."
  },
  {
    "objectID": "lesson_01.html#comparison-between-learning-models-now-vs-back-then",
    "href": "lesson_01.html#comparison-between-learning-models-now-vs-back-then",
    "title": "Lesson 1",
    "section": "Comparison Between Learning Models Now VS Back Then",
    "text": "Comparison Between Learning Models Now VS Back Then\nA surprising question to ask is how was our model able to tell if an image is of a bird or not. Why wasn‚Äôt it able to do earlier?\nLet us explore how image recognition was done in 2012, but before that, it is important to understand a few important terms.\n\n\n\n\n\n\nNote\n\n\n\nThis was not discussed in the lcture, I did a little digging to better understand what was going on and put my learnings here.\n\n\n\nPathology\nA field or a branch of medicine, that deals with studying human tissue for the diagnosis of diseases.\nPathologists basically take samples of the human specimen and study it under microscopes to diagnose some disease, be it cancer, etc.\n\n\nComputational Pathology:\nUsing computer techniques in the process of pathology, i.e., using coding/ML/DL in order to study human tissues and predict the diagnosis of a disease.\n\n\nH&E Images\nWhen a pathologist studies a cell under a microscope, it is easier for him/her to see it clearly, when the cell is stained with some dye.\nA dye is a substance that gives colour to the substrate (to which it is applied to), for distinguishing purposes without chemically bonding with the substrate. Pigments on the other hand chemically bond with the substrate changing its molecular structure.\nIn medicine, the staining is done mostly by two dyes- hematoxylin and eosin.\nHematoxylin shows the ribosomes, chromatin (genetic material) within the nucleus, and other structures in a deep blue-purple colour.\nEosin shows the cytoplasm, collagen, connective tissue, and other structures that surround and support the cell as an orange-pink-red colour.\nHence, staining with hematoxylin and eosin (referred to as H & E staining) helps identify different types of cells and tissues and provides important information about the pattern, shape, and structure of cells in a tissue sample. It is used to help diagnose diseases, such as cancer.\nThe images or samples collected after the staining are called H&E images.\nTo summarize H & E images are images of various cells which are stained with two dyes- hematoxylin and eosin, in order to study them for diagnosis of a disease.\nNow let us get started.\n\n\nThe Story\n\n\n\nML back then\n\n\nIn 2012, at Stanford, a diverse team of computational pathologists did a very successful and very famous project, which was exploring the 5-year survival chances of a cancer patient by looking at their histopathology slides.\nWhat they did back then was a classic Machine Learning approach.\nJeremy spoke to the senior author of the project, Daphne Koller, and asked why they didn‚Äôt use Deep Learning. Apparently, at that time DL wasn‚Äôt on the radar. Hence, this was a pre-deep learning approach.\nOne visible answer to how we are able to create a model for a bird recognizer is because of deep learning. The question then is, What is it exactly that is happening with DL, which could not happen with ML back then? Let us see!\nSo the way they did this, was gathered around a group of experts from multi-disciplinary fields ranging from Mathematicians to Computer Scientists, to Pathologists, and so on, and worked on building and creating this idea for ‚Äúfeatures‚Äù, features they did not even know of to include in their approach for image recognition.\nThere were thousands and thousands of these features. It took a lot of years, a lot of people, a lot of code, and a lot of math.\nOnce they got sufficient features they fed it to an ML model, a logistic regression model in this case.\nComing back to the question earlier, the difference between ML & DL is that DL uses NNs, and NNs don‚Äôt require humans to define any features for it. NNs develop the features themselves as it learns. That was the big difference."
  },
  {
    "objectID": "lesson_01.html#how-dl-learns-features",
    "href": "lesson_01.html#how-dl-learns-features",
    "title": "Lesson 1",
    "section": "How DL Learns Features?",
    "text": "How DL Learns Features?\nIn 2015, Matt Zeiler and Rob Fergus took a trained NN and looked inside it to see what it had learned about the features.\nBut wait?! What do we mean by looking inside a NN? It means looking at the weights.\nSo they looked at the weights inside and drew a picture of them. The following image shows the 9 sets of weights they found each representing a pattern in an image.\n\n\n\nLayer 1\n\n\nDeep Learning is deep because it takes the previous features and combines it with other features to create and detect more advanced features.\n\n\n\nLayer 2\n\n\nSo in neural networks we do not have to hard code these features, but just feed it examples and it will itself learn and recognize it.\n\n\n\nLayer 3\n\n\n\n\n\nLayer 4 & 5\n\n\nThe deeper the NN gets, it finds and detects more deeper features.\nEach of these feature detectors helps NN in understanding an image.\nClearly, trying to hard code would be very difficult.\nWe shall learn ahead how NNs learn this.\nThis is the key difference as said."
  },
  {
    "objectID": "lesson_01.html#image-based-algorithms-go-beyond-images",
    "href": "lesson_01.html#image-based-algorithms-go-beyond-images",
    "title": "Lesson 1",
    "section": "Image Based Algorithms Go Beyond Images",
    "text": "Image Based Algorithms Go Beyond Images\nA general theme can be set up for image based algorithms. But with creativity an image based recognizer can do thing beyond an image. For example:\n\nClassifying Sounds: A sound can be converted into a waveform which is an image and the model can be run on it to classify sounds with state of the art results. \nTime series: One of the students on the forum took a time series and converted it into a picture and used it in the image classifier. \nMotion-Movements: Another student created pictures of mouse-movements from users of a computer. The clicks became dots, the movements became lines, and the speed of the movement was captured in colour. \n\nHence, with creativity, anything non-image type if it can be converted into an image representation can be used in the image classifier model."
  },
  {
    "objectID": "lesson_01.html#myths-around-doing-deep-learning",
    "href": "lesson_01.html#myths-around-doing-deep-learning",
    "title": "Lesson 1",
    "section": "Myths Around Doing Deep Learning",
    "text": "Myths Around Doing Deep Learning\nAs we saw, when we trained a real working bird classifier, we:\n\nDidn‚Äôt use any Math\nDidn‚Äôt use much data (just 400 images)\nDidn‚Äôt use expensive computers\n\nThis is generally the case for the vast majority of doing DL in real life.\nThere will be some Math that will pop up which will be taught as needed or will be referred to external resources.\nThe Myths are passed along by big companies to store lots of data\nMost extraordinary real world projects don‚Äôt need expensive computers or vast data.\nThere are many platforms on which one can do state of the art DL for free.\nOne of the key reasons for this is Transfer Learning, which shall come ahead. Most people do not know about TL.\n\n\n\nCommon myths in doing DL"
  },
  {
    "objectID": "lesson_01.html#pytorch-vs-tensorflow",
    "href": "lesson_01.html#pytorch-vs-tensorflow",
    "title": "Lesson 1",
    "section": "PyTorch VS TensorFlow",
    "text": "PyTorch VS TensorFlow\nIn this course, we will be using PyTorch.\nFolks who are way from the actual DL world would have heard of TensorFlow.\nTF is dying of its popularity in recent years, whereas PyTorch is growing rapidly.\nIn research repositories among the top papers, TF is a tiny minority compared to PyTorch.\nGreat research has come out of Ryan O‚ÄôConnor who also discovered that the majority of researchers using Tf in 2018 have shifted to PyTorch.\nWhat people use in research is a very strong leading indicator of what is going to happen in the industry because it is in research all new papers and algorithms are written about. Once a new paper of high impact factor comes it will bring changes in the research community and it is always better to adapt accordingly. Usually, industry takes some time to adopt these changes, but it will happen soon.\nPyTorch was used very early on when it was released for this course because based on the technical fundamentals it was clear that it was far better.\nHence, PyTorch will be used for this course.\n\n\n\nPyTorch vs TF"
  },
  {
    "objectID": "lesson_01.html#pytorch-has-hairy-code",
    "href": "lesson_01.html#pytorch-has-hairy-code",
    "title": "Lesson 1",
    "section": "PyTorch Has Hairy Code",
    "text": "PyTorch Has Hairy Code\nPyTorch has lengthy codes for relatively simple things.\nFollowing is a code for implementing and optimizer called Adam Optimizer in plain PyTorch taken from the PyTorch repository.\n\n\n\nAn example of hairy code in PyTorch\n\n\nThe grey bit below does the exact same thing using the fast.ai library.\n\n\n\nfast.ai is better\n\n\nfast.ai is a library built by Jeremy and others on top of PyTorch.\nThis huge difference does not indicate that PyTorch is bad, but it reflects the strong foundations on which PyTorch is designed which can be used to build things on top of it, like fast.ai\nWhen we use the fast.ai library, we get access to all the power of PyTorch as well, but we shouldn‚Äôt be writing the former code when we can write the latter.\nThe problem with writing lots of code is there will be lots of things we can mistakes in, lots of things to not have best practices, lot of things to maintain\nIn general it is found that with DL less code is better.\nParticularly, with fast.ai, the code we don‚Äôt write is the code with the practices involved. Hence, using the codes, fast.ai provides, we will get better results.\nfast.ai library is very popular and is widely used in industry, academia, and teaching.\nAs we go with the course we will be seeing pure PyTorch as we go deeper and deeper to see how things work.\nIt won the 2020 best paper award and and hence is well regarded\n\n\n\nfast.ai best paper award"
  },
  {
    "objectID": "lesson_01.html#jupyter-notebook",
    "href": "lesson_01.html#jupyter-notebook",
    "title": "Lesson 1",
    "section": "Jupyter Notebook",
    "text": "Jupyter Notebook\nThe way Jeremy was able to run code snippets as slides was becuase of JNs but not powerpoint.\nHe used an extension called RISE which allows to include code snippets into slides.\nThis will be the environment in which we will be doing most of our computing for the course.\nIts a web based application which is popeular and widely used in industry academia and teaching.\nIts a powerful way to experiment, explore and build."
  },
  {
    "objectID": "lesson_01.html#kaggle",
    "href": "lesson_01.html#kaggle",
    "title": "Lesson 1",
    "section": "Kaggle",
    "text": "Kaggle\nNow adays most people and students run JN not on the computer but on a cloud server.\nOn course.fast.ai we can see various options and how to use them.\nOne of the examples is Kaggle, which not only has competitions but also a cloud notebook server with quite a lot of examples.\nWhen starting with our own NB, just edit it.\nWhen starting with somones elses NB, it will show Copy and Edit.\nUpvote before using others NBs to encourage them and let others know.\nthe first time we do this it says Session Starting meaning its launching.\nIt can be considered as the world‚Äôs most powerful calculator, where we have all the capabilities of all the programming language at our disposal\nThere are two cells, Pros cell and Code cell. One can add pros along with the code which can be helpful in explaining the code to others and ourselves.\nProse are written in markdown.\nOne needs to verify his/her phone number in order to connect to the internet. Do the following before getting started on Kaggle.\n\n\n\nPhone number verification on Kaggle\n\n\n\n\n\nConnecting to the internet on Kaggle\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n! at the start of a line is not Python, but it is a bash shell command."
  },
  {
    "objectID": "lesson_01.html#is-it-a-bird-revisited",
    "href": "lesson_01.html#is-it-a-bird-revisited",
    "title": "Lesson 1",
    "section": "Is It A Bird? Revisited",
    "text": "Is It A Bird? Revisited\n\n\n\n\n\n\nNote\n\n\n\nHere we discuss the code we ran earlier in detail. Note that some minor modifications are there here and there, but in an overall sense it is the same thing.\n\n\nPeople who are new to Python would be surprised that there is very little code. because of the following reasons:\n\nPython is a very concise language, (but not too concise). It has fewer boilerplate than other languages.\nUsing the fast.ai library makes a lot of things convenient for us.\n\n\nfrom duckduckgo_search import ddg_images\nfrom fastcore.all import *\n\ndef search_images(term, max_images=30):\n    print(f\"Searching for '{term}'\")\n    return L(ddg_images(term, max_results=max_images)).itemgot('image')\n\n\nurls = search_images('bird photos', max_images=1)\nurls[0]\n\nSearching for 'bird photos'\n\n\n'https://www.highreshdwallpapers.com/wp-content/uploads/2014/05/Colourful-Flying-Bird.jpg'\n\n\n\nfrom fastdownload import download_url\ndest = 'bird.jpg'\ndownload_url(urls[0], dest, show_progress=False)\n\nfrom fastai.vision.all import *\nim = Image.open(dest)\nim.to_thumb(256,256)\n\n\n\n\nHere we have downloaded and opened an image of a bird.\nfast.ai provides lots of libraries. They ususlly start with fast<something>. For example: * To make it easy to download URLs, fastdownload has download_url. * To make it easy to create a thumbnail, we have im.to_thumb().\n\ndownload_url(search_images('forest photos', max_images=1)[0], 'forest.jpg', show_progress=False)\nImage.open('forest.jpg').to_thumb(256,256)\n\nSearching for 'forest photos'\n\n\n\n\n\nHere we have downloaded an image of a forest.\nNote that we are viewing the image once it is downloaded.\nJeremy always likes to view the data at every step whenever he builds a model. This helps in making sure the data is reasonable. Once they look ok. We can download a bunch of them as follows:\n\nsearches = 'forest','bird'\npath = Path('bird_or_not')\nfrom time import sleep\n\nfor o in searches:\n    dest = (path/o)\n    dest.mkdir(exist_ok=True, parents=True)\n    download_images(dest, urls=search_images(f'{o} photo'))\n    sleep(10)  # Pause between searches to avoid over-loading server\n    download_images(dest, urls=search_images(f'{o} sun photo'))\n    sleep(10)\n    download_images(dest, urls=search_images(f'{o} shade photo'))\n    sleep(10)\n    resize_images(path/o, max_size=400, dest=path/o)\n\nSearching for 'forest photo'\nSearching for 'forest sun photo'\nSearching for 'forest shade photo'\nSearching for 'bird photo'\nSearching for 'bird sun photo'\nSearching for 'bird shade photo'\n\n\nfast.ai has download_images, where if we provide a bunch of URLs, it downloads them. It does this in parallel hence very quickly.\nWe are using resize_images becuase of the following reasons: * In computer vision algorithms we generally don‚Äôt need particularly big images. Hence we are resizing it to maximum size of 400 which makes it much faster. * Since, GPUs are so quick, it can take a whole lot of time to just open an image compared to a NN.\n\nfailed = verify_images(get_image_files(path))\nfailed.map(Path.unlink)\nlen(failed)\n\n0\n\n\nThe above cell finds broken images and deletes them from the dataset.\nJeremy likes to use functional style of programming Python code because of the work he does. The use of .map above gives a sense of it.\nDeveloprs might be familiar with this.\n\ndls = DataBlock(\n    blocks=(ImageBlock, CategoryBlock), \n    get_items=get_image_files, \n    splitter=RandomSplitter(valid_pct=0.2, seed=42),\n    get_y=parent_label,\n    item_tfms=[Resize(192, method='squish')]\n).dataloaders(path, bs=32)\n\ndls.show_batch(max_n=6)\n\n\n\n\nDataBlock is the main thing in this complete model.\nThis is the key thing we must get familiar with as deep learning practitioners at the start of our journey.\nThe question to ask is simply, ‚ÄúHow do I get my data in my model?‚Äù\nThis might be a surprise for the ones thinking that we must spent time in understand neural network architectures, matrix multiplication, gradient, and stuff like that.\nThe truth is very little of all that comes up in practice because at this point of time in the DL world, the community have found resonably small number of models that work for nearly all the main applications we need and fast.ai will create the right type of model for us the vast majority of the time.\nWe will evetually get to all that stuff about tweaking NN architectures in this course, but we will discover that it won‚Äôt be of much use in practice.\nThis is kind of like a similar situation of a CS student, who in a CS course is exposed to the details of compilers and operating systems, but when s/he gets into the real world, none of that is useful.\nThis course is Practical Deep Learning, hence we will focus on the practical part.\nSo let us get started in discussing DataBlock\n\nDataBlock\n\nKey thing to know if we want to know how to use different kinds of datasets.\nWe will be providing it with the following things:\n\n\n\nDataBlock\n\n\nWhen designing DataBlock, Jeremy and his team analysed all the things that changed from project to project to get the data into the right shape. They did this over hundreds of projects and came to realise that they can split it down into these 5 things.\n\n\nblocks: The first thing we tell fast.ai is\n\n\n‚ÄúWhat kind of input we have?‚Äù There are lots of Blocks in fastai for various kinds of inputs. In our case we have our input as an image hence we are using ImageBlock\n‚ÄúWhat kind of output we have?‚Äù The output is a category, one of a number of possibilities. Hence, we use the CategoryBlock.\n\nThis is enough for fast.ai to know what kind of model it needs to build for us.\n\nget_items: The next thing to mention is what are the items that the model will be looking at to train from. We are training from images. Hence, we use get_image_files which is a function we saw earlier. It returns a list of all image files in a path based on extension. So whenever the model needs to find what things to train from it uses this.\nsplitter: It is critical to put aside some data for testing the accuracy of the model. It is called a validation set. It is so crotical that fast.ai doesn‚Äôt allow us to train a model without a validation set. In this case, we randomly (RandomSplitter) ask to set aside 20% of the data.\nget_y: The next question fast.ai asks is ‚ÄúHow does it know the correct label of a photo?‚Äù i.e.¬†how does the model know if a photo is of a bird or a forest. For that we use the parent_folder. It returns the parent folder of the path which was named as bird and forest by us. So that is where the model gets the labels from.\nitem_tfms: Finally, most computer vision architectures need all of the inputs as we train to be of the same size. item_tfms are all of bits of code that is going to run on every item, in this case images. We resize every one of them to being 192x192 pixels. There are two way to resize crop or squish we use squish it.\n\nThis wraps up DataBlock.\nFrom there we create an important class called dataloaders. These are things PyTorch iterates through to grab bunch of our data at a time. The way it dess so fast is because its used GPUs which can do 1000s of things at a time, that means it needs 1000s of things to do. dataloaders feeds the training algorthim with a bunch of images at once, we call it a batch or a mini_batch\nWhen we say show_batch, its a specific term in DL it means show an example of a batch of data that will be passed in the model.\nit tells us two things, the inputs and the label.\nLabels came by calling that parent_folder function.\n\n\n\n\n\n\nExploring the fast.ai documentation\n\n\n\nWhen we come to building our own models, we would want to know the different kinds of splitters, label functions and so forth.\nThis is the best place to go, specially the ‚ÄúTutorials‚Äù section within it.\nStart reading the documentation of something that you are familiar with.\n\n\n\nlearn = vision_learner(dls, resnet18, metrics=error_rate)\nlearn.fine_tune(3)\n\n\n\n\n\n\n\n  \n    \n      epoch\n      train_loss\n      valid_loss\n      error_rate\n      time\n    \n  \n  \n    \n      0\n      0.461070\n      0.107210\n      0.027523\n      00:02\n    \n  \n\n\n\n\n\n\n\n\n\n  \n    \n      epoch\n      train_loss\n      valid_loss\n      error_rate\n      time\n    \n  \n  \n    \n      0\n      0.036630\n      0.011480\n      0.000000\n      00:02\n    \n    \n      1\n      0.020736\n      0.001620\n      0.000000\n      00:02\n    \n    \n      2\n      0.013398\n      0.000982\n      0.000000\n      00:02\n    \n  \n\n\n\nNow we need a model.\nThe critical concept in fast.ai is a learner.\nA learner is something which combines a model, the actual NN function we are training and the data we are using to train it with. Hence, we pass two things- a learner resnet18 and and the data dls (which is the DataBlocks object.\nThere is a relatively small number of learners that will work for the vast majority of things we do.\nIf we pass in bare symbols like resnet18, it uses fast.ai‚Äôs built in models.\nAnother cool thing is that a wonderful library is integrated in fast.ai‚Äôs library built by Ross Wightman called timm. It is the largest collection of computer vision models in the world. And at this point fast.ai is the first and only framework to integrate this.\nHere is a comprehensive list of various models with its information.\nThe model family called resnet will probably be fine for nearly any work we do, but we can use any thing from the above list.\nWhen we run the above cell, it runs pretty fastly, in under 2 minutes. The reason is that somebody has already trained the resnet18 model to recognize over 1 million images of 1000 different types from the ImageNet dataset. After the training they made those weights/parameters available on the internet for anybody to download. By default on fast.ai when we use a model, it downloads those weights for us so that we don‚Äôt start with a NN which can‚Äôt do anything, but start with the one which can do a whole lot. Once we have this NN, a method called as fine tuning takes place which is unique to fast.ai. What it does it takes the pretrained weights that were downloaded by fast.ai and it adjusts them in a carefully controlled way to just teach the model the differences between our data set and what it was originally trained for. Hence the downloading happnes there.\nReaching 100% accuracy.\n\nis_bird,_,probs = learn.predict(PILImage.create('bird.jpg'))\nprint(f\"This is a: {is_bird}.\")\nprint(f\"Probability it's a bird: {probs[0]:.4f}\")\n\n\n\n\n\n\n\n\nThis is a: bird.\nProbability it's a bird: 1.0000\n\n\nIn the previous step we had a leraner which started with a pretrained model and was finetuned for the purpose of our task, now we can call .predict() on it and we pass in an image.\nThis is what the deploying part is which basically achieves our goal we intended to achieve, for example, in the comic we say the person had a reason for the model, to check an image perhaps!"
  },
  {
    "objectID": "lesson_01.html#beyond-image-recognition---segmentation",
    "href": "lesson_01.html#beyond-image-recognition---segmentation",
    "title": "Lesson 1",
    "section": "Beyond Image Recognition - Segmentation",
    "text": "Beyond Image Recognition - Segmentation\n\nWhat Is It?\n\n\n\nSegmentation\n\n\nSegmentation is where we take photos, in this case of road scenes and color the pixels based on the ‚Äúthings‚Äù in the photos, green for trees, brown for buildings, and so on.\nOn the left we have photos were somebody has already classified the pixels and on the right, it is the model who is doing the prediction. Most of the pixels are getting correct.\n\n\nTraining Gives Accurate Results\nOne might assume that this would be a hard task, but the above was trained for 20 sec.¬†Training a little further could easily make it close to perfect.\n\n\nSome Code Analysis\n\n\n\nSegmentation Code Snippet\n\n\nThe steps look familiar as the ‚ÄúIs It A Bird?‚Äù model we ran, in fact in this case the code is a bit less. We are using a simler approach.\nEarlier, we used DataBlocks which is like an intermediate level approach in handling any kind of data and it gives a lot of flexibility.\nFor the kinds of data that occur a lot, one can use DataLoaders which involves less code.\nFor segmentation we use a unet learner which will come in the next lessons.\nRest all is self explanatory and familiar stuff!"
  },
  {
    "objectID": "lesson_01.html#beyond-image-recognition---tabular-analysis",
    "href": "lesson_01.html#beyond-image-recognition---tabular-analysis",
    "title": "Lesson 1",
    "section": "Beyond Image Recognition - Tabular Analysis",
    "text": "Beyond Image Recognition - Tabular Analysis\n\nWhat Is It?\nStepping away from computer vision, the most widely used model in industry is the tabular analysis.\nThe idea is simple, we take spreadsheets or database tables and predict columns of those.\n\n\nSome Code Analysis\n\n\n\nTabular Analysis Code Snippet\n\n\nAgain the code has a sense of similarity.\n\nuntar_data() is a fast.ai feature which downloads the data from a URL and decompresses it. There are whole lot of URLs provided by fast.ai which are the common datasets widely used in learning and research.\nWe created DataLoaders, this time TabularDataLoaders.\ncat_names and cont_names helps in telling the model which colums are categorical and which ones are continuous.\n\n\n\n\nShow Batch\n\n\nThe exact same show_batch can be used to view the data.\nThis is because, fast.ai uses something called ‚Äútype dispatch‚Äù which is a system which popular in the Julia language. It automatically does the right thing for our data regardless of what kind of data it is.\nAs a general sonsolidation, when we use show_batch on something we will get something useful regardles of what kind of data we provided.\n\n\n\nLearner\n\n\nFor the learner we are using tabular learner.\nNote that, this time we are not using fine_tune, but instead fit. This is because for tabular models, there will not be any pre-trained models that can do exactly what we wish to do, because every table has a different structure of data. Pictures have a similarity. Hence, it does not make too much sense to fine-tune a tabular model."
  },
  {
    "objectID": "lesson_01.html#beyond-image-recognition---collaborative-filtering",
    "href": "lesson_01.html#beyond-image-recognition---collaborative-filtering",
    "title": "Lesson 1",
    "section": "Beyond Image Recognition - Collaborative Filtering",
    "text": "Beyond Image Recognition - Collaborative Filtering\n\nWhat Is It?\nThis is the backbone of most recommendation systems today like Amazon, Netflix, etc.\nIt basically takes datasets and analysis the following: * Which users have bought which products? * Which products can the users be interested in based on finding similar users and they like?\nBy similar we mean sharing mutual interets in prodcuts but not based on demography or other parameters.\n\n\nSome Code Analysis\n\n\n\nCollaborative Filtering Code Snippet 1\n\n\nWe are using ColabDataLoaders, where we can include the data using a csv file.\nGenerally all Collab Filtering have the similar data structure shown in the batches above.\n\n\n\nCollaborative Filtering Code Snippet 2\n\n\nWe are using the collab_learner where we pass in the data dls along with an additional information y_range. We do this becuase what we are predicting is not a catgory but a real numbers. Hence the possible range is mentioned. Note that the actual range is 1-5 but we use a range from a little bit lower to a little bit higher, that‚Äôs why we used 0.5-5.5. We will learn the reasons for this in the upcoming lessons.\nIdeally we should fit it instead of fine-tuning but it works as well in collaborative filtering.\n\n\n\nshow_results()\n\n\nFor any kind of models we can always call show_results which shows few examples."
  },
  {
    "objectID": "lesson_01.html#what-jeremy-makes-with-jupyter-nbs",
    "href": "lesson_01.html#what-jeremy-makes-with-jupyter-nbs",
    "title": "Lesson 1",
    "section": "What Jeremy Makes With Jupyter NBs",
    "text": "What Jeremy Makes With Jupyter NBs\n\nThe Deep Learning for Coders with fastai and PyTorch textbook was written in JNs. Here is the repo.\nThe entire fast.ai library was written in NBs. Here is the repo. Since all the source codes are NBs, it has actual pictures of things that were being built.\nBlogging. Blogging is easy when done with JNs if there is lots of code involved. It displays the outputs as well, like the one you are reading now :D. This blog was written in NBs.\nAll of fast.ai libraries tests and continuous integration is all NBs. Every time changes are made in the NBs, multiple tests are run automatically."
  },
  {
    "objectID": "lesson_01.html#what-can-dl-do-at-present",
    "href": "lesson_01.html#what-can-dl-do-at-present",
    "title": "Lesson 1",
    "section": "What Can DL Do At Present?",
    "text": "What Can DL Do At Present?\nWe are still scratching the tip of an iceberg!\nAlthough to day it is really hyped and marketed about, in 2014 things were a bit dull: * Not many people were talking about DL. * There was no accessible way to get startet with it. * There were no pretrained models one could download. * It was just starting to appear- some open source softwares were running on GPUs.\nDespite all that DL is doing pretty well today but we are still scratching the surface.\nPeople working in any domain who wish to use DL, months after their implementation get state of the art results in their fields.\nFollowing are the areas in which most people have tried DL so far, still most things haven‚Äôt been tried.\n\n\n\nList of things DL can do\n\n\n\n\n\nList of things DL can do\n\n\nJeremy has tried to make bigger lists and ended up making pages. It is spread out everywhere!\nGenerally speaking DL will be good at tasks that a human can do resonably quickly, like looking at a GO board and deciding if it is a good GO board or not.\nIf the task is something that takes lots of logical thought processes and not based on data, then DL wouldn‚Äôt fit there, like deciding who would win an election."
  },
  {
    "objectID": "lesson_01.html#a-quick-history-of-dl",
    "href": "lesson_01.html#a-quick-history-of-dl",
    "title": "Lesson 1",
    "section": "A Quick History Of DL",
    "text": "A Quick History Of DL\nDl is incredibly powerful today but it took decades of hardwork by lot of people to reach where we are today.\nBelow is the first neural network, the basis of DL:\n\n\n\nNN back then\n\n\nThe basic ideas have not changed at all, although we have extra gear at our disposal, things like GPUs, solid-state drives, and of course lots of data."
  },
  {
    "objectID": "lesson_01.html#high-level-overview-of-models",
    "href": "lesson_01.html#high-level-overview-of-models",
    "title": "Lesson 1",
    "section": "High Level Overview Of Models",
    "text": "High Level Overview Of Models\nLet us take a look at what is going on in a model works, and discuss the basic idea of ML from a very high level.\nFollowing is what a normal program looks like in the pre DL/ML days:\n\n\n\nA normal computer program\n\n\nWe have inputs and results, and a program coded in the middle that has bunch of conditionals, loop, and blah blah blah.\nA machine learning model does not look that different:\n\n\n\nA machine learning model\n\n\nHere: * The program is replaced by a model. * We don‚Äôt just have inputs now but something called as weights, which are called as parameters as well.\nThe key thing being that the model is no longer a bunch of conditionals or loops, but is a mathematical function.\nAn example is the Neural Network. Following is how it works:\nIt takes the inputs, multiplies it by one set of weights, and adds them up. It does this process again for a second set of weights and so on. It takes any resulting negative numbers and replaces with zeroes. It then takes these as new inputs for the next layer and repeats the whole process of multiplying and adding with the weights till the next layers.\nThe model does not to anything useful unless the weights are chosen carefully. To begin wiith we start by starting with some random weights. Initially it doesn;t do anything useful.\nWe do the following, as described in the 1950s by Arthur Samuel, the inventor of ML.\n\n\n\nA machine learning model\n\n\n\nTake the inputs and weights\nPut it in the model\nGet the results\nDecide how good they are\n\nFor example, if we are trying to decide if a picture is of a bird or not and the model, which initially is taking a random weight said otherwise, we then calculate the loss. It is number which says how good the results are. We can for example say what‚Äôs the accuracy.\nThe critical step is the ‚Äúupdating step‚Äù where we update the weights with a new set which is a bit better than the previous weights, by bit better we mean the loss should get a little bit better. So, we need a mechanism which does this updateing process.\nIn an overall sense, if we make it a little bit better enough no of times we get what we want."
  },
  {
    "objectID": "lesson_01.html#learner-backgrounds",
    "href": "lesson_01.html#learner-backgrounds",
    "title": "Lesson 1",
    "section": "Learner Backgrounds",
    "text": "Learner Backgrounds\nFor learners who are already familiar with NBs and Python this lesson will be easy- just using NBs and some new libraries.\nFor those who do not know Python are biting at a big thing here. There will be lots to learn.\nPython will not be taught in this course but there are great Python resources on the forum."
  },
  {
    "objectID": "lesson_01.html#hwthings-to-do-before-moving-to-lesson-2",
    "href": "lesson_01.html#hwthings-to-do-before-moving-to-lesson-2",
    "title": "Lesson 1",
    "section": "HW/Things To Do Before Moving To Lesson 2",
    "text": "HW/Things To Do Before Moving To Lesson 2\n\n1. Experiment!\nRegardless of where you are at, the most important thing is to experiment. Experimenting can mean the following: 1. Simply running the Kaggle NBs- just see them run. 2. Changing things a little bit * Instead of bird and forest come up with something else. * Instead of using only 2 categories, try to use 3 or more categories.\nDepeding on whereever you are at, try to push yourself a little bit but not too much before moving into the next lesson.\n\n\n2. Read chapter 1 of the textbook\nChapter 1 has got much the same stuff presented in a slightly different way.\n\n\n3. Share Your Work\nOne can share on this thread of the forum.\nIt is amazing to see learner‚Äôs journeys once they begin to share their work. In the first year of the course there were 1000s of replies of learners sharing their work, and of those replies many of them had turend into many startups, scietific papers, and job offers. Some of them were just fun projects!\n\n\n4. Have A Look At The Quiz Questions\nTry to see if you can answer them all correctly\n\n\n\nFigure : Share Your Work thread on forum"
  },
  {
    "objectID": "lesson_01.html#glimspes-of-other-students-work",
    "href": "lesson_01.html#glimspes-of-other-students-work",
    "title": "Lesson 1",
    "section": "Glimspes Of Other Student‚Äôs Work",
    "text": "Glimspes Of Other Student‚Äôs Work\nThe projects people do are based on where they live and what there intrerests are. Following are a few of them.\n\nTrinidad & Tobago Classifier:\n\n\n\nTrinidad & Tobago Classifier\n\n\nZucchini & Cucumber Classifier:\n\n\n\nVegetable classifier project by a student\n\n\nSatellite City Imagery Classifier:\n\n\n\nSatellite city image classifier project by a student\n\n\nPanama City Bus Classifier:\n\n\n\nBus classifier project by a student\n\n\nBatik Cloth Classifier:\n\n\n\nCloth classsifier project by a student\n\n\nBuilding Safety:\n\n\n\nDisaster management project by a student\n\n\nThis is a practicallyy important one, recognising state of the buildings. Quite a few students have moved into disaster resellience domains banes on satellite imagery.\nSound Classification (Revisited):\n\n\n\nSound classification project by a student\n\n\nCancer Tumour:\n\n\n\nCancer tumout detection project by a student\n\n\nFraud Detection (Revisited):\n\n\n\nFraud detection project by a student\n\n\nEnvision Startup:\n\n\n\n\nEnvision a startup created by a student\n\n\nHave a go at building your own project and try to push a little further."
  },
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "Blog",
    "section": "",
    "text": "Thus Wrote Samar\n\n\n\n\n\nMy first blogpost\n\n\n\n\n\n\nAug 10, 2023\n\n\nSamar Zayan\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "tvseries.html",
    "href": "tvseries.html",
    "title": "Samar Zayan",
    "section": "",
    "text": "TV Series"
  },
  {
    "objectID": "music.html",
    "href": "music.html",
    "title": "Samar Zayan",
    "section": "",
    "text": "Music"
  },
  {
    "objectID": "lesson0.html#about",
    "href": "lesson0.html#about",
    "title": "Lesson 0",
    "section": "About",
    "text": "About\nThis was an entirely optional presentation that was given in 2021 titled as Lesson 0.\n\n\n\nFigure 1: ‚ÄúHow to fast.ai‚Äù\n\n\nThis lesson is a perfect guide on ‚ÄúHow To fast.ai?‚Äù\nIt helps a learner in knowing:\n\nHow to get the most out of this course?\nHow to make sure s/he finishes it?\nHow to make sure it has been a productive learning experience?\n\nIn an overall sense, this lesson gears a learner with the best approaches to this course which Jeremy heard from various students.\nMost often, some students, only after finishing the course, when they reach the end, realize what to do and what not to do and they begin again from the start. To avoid this does not happen, the tips shared in this lesson will be quite helpful.\nApart from all this, the lesson depicts the actual mechanics of setting up two environments, Google Colab and AWS EC2, discussing preferences over one another. This is what we will be using while actually coding.\n\n\n\n\n\n\nNote\n\n\n\nThe coding environment is different in the 2022 version of the course. Hence, this setup may not be relevant for those takng the 2022 version."
  },
  {
    "objectID": "lesson0.html#outcomes-of-students-who-completed-the-course",
    "href": "lesson0.html#outcomes-of-students-who-completed-the-course",
    "title": "Lesson 0",
    "section": "Outcomes Of Students Who Completed The Course",
    "text": "Outcomes Of Students Who Completed The Course\nMany stdents, as in hundreds and thousands of students after going through this course went on to:\n\nCreate successful startups.\nWrite research papers with high impact factors.\nCreate new products for their companies.\n\nThis course is a well-proven course which won a lot of awards."
  },
  {
    "objectID": "lesson0.html#two-types-of-learners",
    "href": "lesson0.html#two-types-of-learners",
    "title": "Lesson 0",
    "section": "Two Types Of Learners",
    "text": "Two Types Of Learners\nThere will always be two types of students. One who will finish the course and the second who will not.\nThe delightful success stories of students are only meant for the ones who actually completed the course.\nDecide for yourself if you want to finish the course or not. It does take a lot in finishing the course as will be explained ahead."
  },
  {
    "objectID": "lesson0.html#the-fast.ai-textbook",
    "href": "lesson0.html#the-fast.ai-textbook",
    "title": "Lesson 0",
    "section": "The fast.ai Textbook",
    "text": "The fast.ai Textbook\nThere is an actual textbook written by Jeremy and Sylvain Gugger which can be followed along with the course.\n\n\n\nFigure 2: fast.ai textbook\n\n\nThe textbook is available for purchase on Amazon and is also available for free on Github as a fastbook repo.\nIt was written in Jupyter Notebooks and then a software was written to convert that into the textbook.\nPeople like the book.\nOn a side note, Jeremy does not make any profit from the book, so he says don‚Äôt buy the book in order to thank him, but buy the book if you, the learner wants it, else one can read it for free if that works.\nThe books looks really great on any format be it Kindle or Paperback, unlike most of the technical textbooks."
  },
  {
    "objectID": "lesson0.html#the-course",
    "href": "lesson0.html#the-course",
    "title": "Lesson 0",
    "section": "The Course",
    "text": "The Course\nPart 1 of the course goes through the initial half of the textbook and Part 2 for the latter half of the book. Each lesson covers a chapter or so of the book.\n\n\n\n\n\n\nNote\n\n\n\nThis was back in the 2021 version of the course. I need to verify the overlap as of 2022."
  },
  {
    "objectID": "lesson0.html#finish-the-damn-course",
    "href": "lesson0.html#finish-the-damn-course",
    "title": "Lesson 0",
    "section": "Finish The Damn Course!",
    "text": "Finish The Damn Course!\n\n\n\nFigure 3: Finish It\n\n\nGet it through your head to finish the course or finish half of the textbook.\nMost people who come in drift away after a few days or weeks and don‚Äôt finish it.\nStructure your time and create a practical schedule and stick to it. ‚ÄúWhat day are you going to watch the lesson?‚Äù, ‚ÄúWhat day are you going to do the assignments?‚Äù\nIf the learner‚Äôs intention upfront is not to finish the course, that is fine. But, if someones joins the course to with an intention to finish it and be an effective deep learning practitioner, must finish it off!\ntell your friends/spouse that it is your goal so that you get that social pressure which can help you finish it off.\n\n\n\n\n\n\nTip\n\n\n\nI told my brother, and he keeps asking me now and then, how it‚Äôs going! It helps me get back to it incase I drift away. Pick anything that works for you."
  },
  {
    "objectID": "lesson0.html#do-a-project",
    "href": "lesson0.html#do-a-project",
    "title": "Lesson 0",
    "section": "Do ‚ÄòA‚Äô Project",
    "text": "Do ‚ÄòA‚Äô Project\nApart from finishing the course, finish one polished project."
  },
  {
    "objectID": "lesson0.html#simple-goal",
    "href": "lesson0.html#simple-goal",
    "title": "Lesson 0",
    "section": "Simple Goal",
    "text": "Simple Goal\nSo to summarize, this is what a learner has gotta do:\n\nFinish the course.\nFinish one project."
  },
  {
    "objectID": "lesson0.html#importance-of-a-project",
    "href": "lesson0.html#importance-of-a-project",
    "title": "Lesson 0",
    "section": "Importance Of A Project",
    "text": "Importance Of A Project\nIt is only through one well-crafted project we can show off our skills and get recognized.\nOne of the former students and a fantastic alumni, Christine McLeavy who now is at OpenAI, one of the top research organizations took this advice to heart given by Jeremy back then and made a fantastic AI system that could create new music using Deep Learning. Her work was featured and played on the BBC orchestra and helped her get the exclusive job at OpenAI\n\n\n\nFigure 4: McCleavy sharing her insights in a postcast with Sanyam, another former student\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe podcast can listened here."
  },
  {
    "objectID": "lesson0.html#about-the-project",
    "href": "lesson0.html#about-the-project",
    "title": "Lesson 0",
    "section": "About The Project",
    "text": "About The Project\n\nThe project need not be something that no one built before. If you have found a very cool project done by others, you can create your own version too. That is fine!\nThe project need not be world-changing.\n\n\nOne of the students built a project for his fiancee that could recognize cousins.\nOne of the students built an app called ‚ÄúHot Dog Or Not Hot Dog‚Äù that was featured in the Silicon Valley TV series. It basically allows a user to take a pic of a food item and tell if it is a hot dog or not. (The Clip)\n\n\nOr it can solve medicine as well :D!"
  },
  {
    "objectID": "lesson0.html#on-being-tenacious",
    "href": "lesson0.html#on-being-tenacious",
    "title": "Lesson 0",
    "section": "On Being Tenacious",
    "text": "On Being Tenacious\nTenacious means sticking to something till the end. This was found as the single most trait found among students who successfully completed the course.\nA thousand hurdles will come our way in various forms and we must learn to pick ourselves back.\nTenacity is something we can choose! Just come back even if it is after a few months or even a year.\n\n\n\nFigure 5: On tenacity"
  },
  {
    "objectID": "lesson0.html#radek-and-his-inspiring-story",
    "href": "lesson0.html#radek-and-his-inspiring-story",
    "title": "Lesson 0",
    "section": "Radek And His Inspiring Story",
    "text": "Radek And His Inspiring Story\nRadek is one of the top alumni of the course and his story of making it big in ML is very inspiring.\nFrom being someone without a degree, not knowing how to code, and being stuck in a boring job, Radek made his way to winning Kaggle competitions and working in a medical AI startup . Currently, he is working in a nonprofit which is working on translating animal language.\nHe began his journey but failed many many times. He comprised all of his learning in the book Meta-learning.\nIt is good to have some role models when beginning the Deep Learning journey and Radek is a very good one.\n\n\n\nFigure 6: Radek Insights"
  },
  {
    "objectID": "lesson0.html#important-insights-from-the-meta-learning-book",
    "href": "lesson0.html#important-insights-from-the-meta-learning-book",
    "title": "Lesson 0",
    "section": "Important Insights From The ‚ÄúMeta Learning‚Äù Book",
    "text": "Important Insights From The ‚ÄúMeta Learning‚Äù Book\n\nDo not keep preparing to do the course or the project. Just start!\n\n\nSome students go on jumping from MOOC to MOOC studying all sorts of things and they never start.\nDon‚Äôt worry about the unknown stuff. The course will help us along the way. \n\n\nIf one has no coding experience, s/he can take this opportunity to learn to Code. Harvard‚Äôs CS50 is a good resource. \nThere are a few topics that are expected to know as a CS student but are never taught. Some MIT students have created a lovely course that will help us learn these things and they called it The Missing Semester Of Your CS Education. This will help build the software environment foundations. \n\n\n\n\n\n\n\nTip\n\n\n\nAs of 2022, the Live Coding playlist can help in setting up the necessary software environment replacing The Missing Semester Of Your CS Education in my opinion."
  },
  {
    "objectID": "lesson0.html#share-your-work",
    "href": "lesson0.html#share-your-work",
    "title": "Lesson 0",
    "section": "Share Your Work",
    "text": "Share Your Work\nSharing the work and communicating it is a great way for us to enhance the learning process as well as make a brand or portfolio for us as we progress.\nGet rid of the discomfort, fear, and anxiety of getting exposed and just share it.\n\n\n\nFigure 10: Radek on sharing the work"
  },
  {
    "objectID": "lesson0.html#steps-of-doing-a-lesson",
    "href": "lesson0.html#steps-of-doing-a-lesson",
    "title": "Lesson 0",
    "section": "4 Steps Of ‚ÄòDoing‚Äô A Lesson",
    "text": "4 Steps Of ‚ÄòDoing‚Äô A Lesson\nStep 1: Watch the lecture/Read a chapter from the book\nStep 2: a) Run the notebook b) Experiment with it, by trying to tweak things.\nStep 3: Reproduce the notebook from scratch\nStep 4: Try to run with different data sets\n\n\n\nFigure 11: 4 steps of doing a lesson\n\n\nDo not worry if you can‚Äôt do all this from Week 1 right away. Move along and come back to do these cycles.\nOnce you have done all this, either at the starting or after coming back, you can confidently say that you have completed the lesson and extracted its juice."
  },
  {
    "objectID": "lesson0.html#notebook-servers-vs-linux-servers",
    "href": "lesson0.html#notebook-servers-vs-linux-servers",
    "title": "Lesson 0",
    "section": "Notebook Servers VS Linux Servers",
    "text": "Notebook Servers VS Linux Servers\nFor the actual coding environment, we have two options: 1. Using Notebooks 2. Using Linux\nWe have cloud servers for both of these categories, so we need not worry about setting them up on our local computers or laptops. Meaning even if one doesn‚Äôt have Jupyter Notebook installed, one can use the Notebook servers mentioned. Even if one doesn‚Äôt have a Linux operating system, one can use the Linux servers mentioned.\nThe Notebook servers provided at the site will have all the code written and we just have to run it. It is simple for beginners. One can begin with this for the initial weeks.\nUsing Linux is the professional way of doing it. This is how things will be done at jobs or startups. Initially one can skip this, but it will be highly effective if we can go through this process of doing things.\nOnce we start to feel comfortable running the notebooks after Week 1 or Week 2, we can switch to the Linux servers."
  },
  {
    "objectID": "lesson0.html#tutorial-on-getting-started-with-colab",
    "href": "lesson0.html#tutorial-on-getting-started-with-colab",
    "title": "Lesson 0",
    "section": "Tutorial On Getting Started With Colab",
    "text": "Tutorial On Getting Started With Colab\nPractical demonstration in the video, better to watch the part.\n\n\n\n\n\n\nTip\n\n\n\nNot relevant for the 2022 course as we use Kaggle NBs."
  },
  {
    "objectID": "lesson0.html#how-to-not-do-fast.ai",
    "href": "lesson0.html#how-to-not-do-fast.ai",
    "title": "Lesson 0",
    "section": "How To Not Do fast.ai",
    "text": "How To Not Do fast.ai\nBy NOT building models.\nThroughout the course, the sole purpose and the central activity of a learner must be running and building models. If a learner is not doing this, and instead, learning other things like Calculus, Real Analysis, etc. then s/he must stop and get back to building models. The course is meant for people who want to build models.\n\n\n\nFigure 12: How Not To Do fast.ai"
  },
  {
    "objectID": "lesson0.html#get-feedback-through-practicing",
    "href": "lesson0.html#get-feedback-through-practicing",
    "title": "Lesson 0",
    "section": "Get Feedback Through Practicing",
    "text": "Get Feedback Through Practicing\nPracticality is at the heart of really doing this course.\nFind a way to measure what is working vs what is not working through practically creating a model. Most of the learners will sense positive feedback from Week 1 when they see they have built a cool model.\nIf you have read a research paper or something and you sense that you have elevated your understanding, then implement it. One cup of theory and one cup of practice!\n\n\n\nFigure 13: Right combination of theory & practice"
  },
  {
    "objectID": "lesson0.html#read-write-code-throughout-the-course",
    "href": "lesson0.html#read-write-code-throughout-the-course",
    "title": "Lesson 0",
    "section": "Read & Write Code Throughout The Course",
    "text": "Read & Write Code Throughout The Course\nOne of the major outcomes of the course is that a learner can transform him/herself into a better developer than he/she is at the beginning.\nAnd this happens only if we do the following throughout the course: 1. Read Code 2. Write Code\nRead the fast.ai source codes, read the notebook codes, read code written by others and write your own code.\n\n\n\nFigure 14: Read & write code"
  },
  {
    "objectID": "lesson0.html#twitter-access-the-dl-world-through-it",
    "href": "lesson0.html#twitter-access-the-dl-world-through-it",
    "title": "Lesson 0",
    "section": "Twitter: Access The DL World Through It",
    "text": "Twitter: Access The DL World Through It\nThrough Twitter, one can access the whole world of DL and AI. Create a feed filled with cool and interesting things on DL and read it every day. Initially, we might understand only 0.5% of what the tweets are about but it is fine. We will slowly expand our horizons. \nTo get started:\n\nGet on Twitter\nFollow Jeremy\nGo to his likes, and follow people who you find interesting\n\nTweet your work as you progress and get recognized."
  },
  {
    "objectID": "lesson0.html#start-blogging",
    "href": "lesson0.html#start-blogging",
    "title": "Lesson 0",
    "section": "Start Blogging",
    "text": "Start Blogging\nBlogging takes us beyond twitter.\nBlogging is not about what we had for dinner or about what our morning routines are like.\nThis blog post can be a great convincing for you!\n\n\nWhat to write in a blog?\nFollowing are a few suggestions:\n\nAn idea we can keep in mind to begin blogging is this, ‚ÄúWhat things if I would have known a few months ago, would have helped me.‚Äù There is always going to be someone who is one step behind us, and it can be helpful to them.\n\nConvert a video or a talk and convert it into a blog.\n\n\nAn example: Aman Arora one of the fast.ai alums converted Jeremy‚Äôs talk into a blog.\nBenefits: People will be grateful to you and you can get recognized. The blog that Aman wrote was shared and highlighted by the CEO of Data61 which is a top Data Science body in Australia on LinkedIn.\nMost people prefer reading over watching a video and it can be helpful to them. You will learn and be useful at the same time.\n\n\n\n\nWhere to write?\nFollowing are some easy to get started on the blogging journey. There is no reason for us to not to start blogging. 1. Fastpages * One cool thing about this is that we can convert documents and notebooks into blogs easily. * It is in Github, so as we blog, we will learn about Git. * It uses Markdown, which will help us learn it as we blog 2. Google Sites If you feel intimidated with Git you can hop on to Google Sites. It has various themes we can use. 3. Medium If you still think that Google Sites is time-consuming to get started you can start away at medium.\n\n\n\n\n\n\nTip\n\n\n\nAs of 2022, Quarto is a far better option than fastpages. This thread explains it in detail."
  },
  {
    "objectID": "lesson0.html#ml-coding-vs-other-coding",
    "href": "lesson0.html#ml-coding-vs-other-coding",
    "title": "Lesson 0",
    "section": "ML Coding VS Other Coding",
    "text": "ML Coding VS Other Coding\nThe key feature of ML Coding is generalization.\nOnce an ML Code is written and trained with one set of data, it can be applied to another set of data and get good results.\nEven the pieces of codes we explore in the course have a strong ability to generalize themselves across various other types of data. So as we progress with the course, whenever we learn to build a model, one key question to ask constantly is ‚ÄúHow will this model generalize well?‚Äù. We need to learn measures of generalizations.\nThe places where it can generalize are broad, be it a Kaggle competition or a prototype, or a production unit at work.\n\n\n\nFigure 16: Hidden gem of ML"
  },
  {
    "objectID": "lesson0.html#importance-of-a-good-validation-set",
    "href": "lesson0.html#importance-of-a-good-validation-set",
    "title": "Lesson 0",
    "section": "Importance Of A Good Validation Set",
    "text": "Importance Of A Good Validation Set\nWe will learn about validation sets in Lesson 1, but Jeremy wanted to highlight the importance of selecting a good validation set here.\nThe basic idea is this, in order to create a model which is really good and can be generalized well, we need to use data that facilitates well for the model so that it can be applied in real life.\nRead this for more info."
  },
  {
    "objectID": "lesson0.html#ml-code-is-hard-to-write",
    "href": "lesson0.html#ml-code-is-hard-to-write",
    "title": "Lesson 0",
    "section": "ML Code Is Hard To Write",
    "text": "ML Code Is Hard To Write\n\n\n\nFigure 17: Radek‚Äôs insights\n\n\nJeremy always assumes that every line of ML code he writes is wrong and according to him he is right most of the time.\nAlthough there can be many ways the code can be wrong, one of the reasons for the hardness of writing ML code arises because most of the time we can not see we are wrong, unlike the usual software work, we can at least see our errors in front of us.\nSome examples which might remain hidden are as follows:\n\nSome random set of images being upside down and it got into the system.\nName not being stored in the database.\nTitle is not centered\n\nTo fix this we need to begin by creating a baseline for a project."
  },
  {
    "objectID": "lesson0.html#baseline-for-projects",
    "href": "lesson0.html#baseline-for-projects",
    "title": "Lesson 0",
    "section": "Baseline For Projects",
    "text": "Baseline For Projects\n\n\n\nFigure 18: On baseline for projects\n\n\nWhen beginning to do a project, we must begin first by creating a simple baseline and creating the simplest model we can.\n\n\n\n\n\n\nImportant\n\n\n\nCommon mistakes: Trying to do a very big high-level complicated project for months and failing it.\n\n\n‚ÄúSuccessful ML models are built in the simplest possible ways which begin first by sending something from end-to-end first, and then are slowly incrementing it.‚Äù\nIt might feel very silly and dumb, to begin with, but that‚Äôs how all the pros do it."
  },
  {
    "objectID": "lesson0.html#kaggle-competitions-as-projects",
    "href": "lesson0.html#kaggle-competitions-as-projects",
    "title": "Lesson 0",
    "section": "Kaggle Competitions As Projects",
    "text": "Kaggle Competitions As Projects\nKaggle Competitions can be used as good HWs and doing projects. Begin on your first Kaggle competition, not as a competitor but just to learn. Pick a competition and go through the complete process of finishing it. It will teach us a lot. After a few months, you will be much developed in our learning and who knows we might even come in the top 50%.\nKaggle is closer to the real world and not completely representative, which makes it easier for us not to worry about deployment and inference speed but gives us that end-to-end experience.\n\n\n\nFigure 19: On Kaggle Competitions"
  },
  {
    "objectID": "lesson0.html#on-finding-a-job",
    "href": "lesson0.html#on-finding-a-job",
    "title": "Lesson 0",
    "section": "On Finding A Job",
    "text": "On Finding A Job\nLearners who completed Fast.ai course went on to grab very very great jobs.\nAs we progress with the course, we can parallelly build our job portfolios. Our job portfolios will be everything from posts on the forums, blogs we write, Github repositories, participation in Kaggle, and so on.\nThe standard big old companies might not understand the influence and depth of our work as most of the profiles are reviewed by HR members.\nHowever, startups and many other companies can truly grasp our potential based on our impact on Github, Kaggle, etc.\n\n\n\nFigure 20: On finding a job"
  },
  {
    "objectID": "lesson0.html#closing",
    "href": "lesson0.html#closing",
    "title": "Lesson 0",
    "section": "Closing",
    "text": "Closing\nAnother reason to finish this course, is to allow oneself to move beyond it doing the next course which is the part 2.\n\n\n\n\n\n\n\nNote\n\n\n\nThe end section of the lesson covers setting up the software background such as AWS EC2. I haven‚Äôt included its summary becuase the software setup is different in the 2022 version, it was not relevant. The software setups will be covered in the regular lessons of the 2022 course."
  },
  {
    "objectID": "safedriving.html",
    "href": "safedriving.html",
    "title": "Samar Zayan",
    "section": "",
    "text": "lesson 1"
  },
  {
    "objectID": "technical_glossary.html",
    "href": "technical_glossary.html",
    "title": "Technical Glossary",
    "section": "",
    "text": "Following are the lists of all the technical terms I have encountered so far.\nBased on my curiosity and requirement of understanding, I have put up the content. It can serve as a first hand guide.\n\n\n\n\n\n\n   \n     \n     \n       Order By\n       Default\n         \n          Title\n        \n         \n          Author\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\nTitle\n\n\nAuthor\n\n\n\n\n\n\n-Uqq\n\n\n\n\n\n\npip\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "practicaldeeplearning.html",
    "href": "practicaldeeplearning.html",
    "title": "Samar Zayan",
    "section": "",
    "text": "PDL"
  },
  {
    "objectID": "live_coding_2.html",
    "href": "live_coding_2.html",
    "title": "Samar Zayan",
    "section": "",
    "text": "LC 2"
  },
  {
    "objectID": "fast.ai.html",
    "href": "fast.ai.html",
    "title": "fast.ai",
    "section": "",
    "text": "Here I share all my learnings I gained from the fast.ai metaverse!\nBe it from courses like Practical Deep Learning for Coders or from playlists like Live Coding or talks given by Jeremy Howard or Rachel Thomas and so on.\nYou get the idea!"
  },
  {
    "objectID": "fast.ai.html#my-learning-goals",
    "href": "fast.ai.html#my-learning-goals",
    "title": "fast.ai",
    "section": "My Learning Goals",
    "text": "My Learning Goals\nI hae set up the following targets for myself:\n\nFinish Practical Deep Learning for Coders by the end of 2022.\nFinish From Deep Learning Foundations to Stable Diffusion by the first quarter of 2023."
  },
  {
    "objectID": "favourites.html",
    "href": "favourites.html",
    "title": "Samar Zayan",
    "section": "",
    "text": "Fav"
  },
  {
    "objectID": "books.html",
    "href": "books.html",
    "title": "Samar Zayan",
    "section": "",
    "text": "Books"
  },
  {
    "objectID": "live_coding_1.html",
    "href": "live_coding_1.html",
    "title": "Samar Zayan",
    "section": "",
    "text": "LC 1"
  },
  {
    "objectID": "glossary/pip/index.html",
    "href": "glossary/pip/index.html",
    "title": "pip",
    "section": "",
    "text": "It stands for ‚ÄúPackage Installer for Python‚Äù\nUsed for installing (and uninstalling) software packages\nIt connects to an online repository called Python Package Index (which has many public packages) searches for the required package in it and installs it on the system. This means that most of the public packages we download are exists in this repository PyPI. One can add their own packages to PyPI for users around the globe to use it.\nApart from the PyPI repository pip can also be configured to connect to other package repositories (local or remote), provided that they comply with¬†Python Enhancement Proposal ¬†503.\npip is case-insensitive, i.e.¬†one can type PIP or PiP or piP etc.\npip install is used as a separate command in the shell itself to install the required package. It is a shell command. Whereas¬†!pip install can be used inside a program as a statement that installs the required package while executing the program in which it is used. The exclamation mark ! must be put if we want to enter a shell command."
  },
  {
    "objectID": "glossary/uqq/index.html",
    "href": "glossary/uqq/index.html",
    "title": "-Uqq",
    "section": "",
    "text": "U stands for an upgrade. It upgrades all specified packages to the newest available version.\nq stands for quiet. It hides certain messages and gives less output not polluting the coding environment with unnecessary outputs that occur during installation.\nWhen installing a package, a process of logging happens usually in 3 steps and at each step, the corresponding logging message gets displayed as an output. These are:\n\nWARNING messages\nERROR messages\nCRITICAL messages\n\nThe q is used to suppress these messages (outputs) in an additive fashion as follows:\n\n-q:   hide WARNING messages\n-qq:  hide WARNING and ERROR messages\n-qqq: hide all messages"
  },
  {
    "objectID": "lesson1.html#introduction",
    "href": "lesson1.html#introduction",
    "title": "Lesson 1",
    "section": "Introduction",
    "text": "Introduction\nWelcome to Practical Deep Learning For Coders!\nThis is the fifth version of the course.\nIt‚Äôs the first new one that has been done in 2 years since the previous version in 2020 and a lot of cool new things have come up along the way to cover.\n\n\n\nFigure 1: fast.ai 2022"
  },
  {
    "objectID": "lesson1.html#a-big-jump-since-2015",
    "href": "lesson1.html#a-big-jump-since-2015",
    "title": "Lesson 1",
    "section": "A Big Jump Since 2015",
    "text": "A Big Jump Since 2015\nIt is amazing how much things have changed.\nBelow is an xkcd (highly popular among most coders and alike) comic from the end of 2015 which depicts the situation back then.\n\n\n\nFigure 2: An xkcd joke\n\n\nIt can be hard to tell what‚Äôs easy and what‚Äôs impossible in computing.\nIn 2015 it was nearly impossible to create a code that can check if an image is of a bird or not! So impossible that it became the idea of a joke.\nNow in 2022, we can pull it off for free in under 2 minutes."
  },
  {
    "objectID": "lesson1.html#is-it-a-bird",
    "href": "lesson1.html#is-it-a-bird",
    "title": "Lesson 1",
    "section": "Is It A Bird?",
    "text": "Is It A Bird?\nThe following Python code does it for us. Surprisingly there is very little code. because of the following reasons:\n\nPython is a very concise language, (but not too concise). It has fewer boilerplate than other languages.\nUsing the fast.ai library makes a lot of things convenient for us.\n\n\n!pip install -Uqq fastai\n\nWhenever using a cloud platform like Colab or JNs in Kaggle, it is a good practice to have this cell at the top. Running the above cell makes sure that the most recent version of any library/software is used. Older versions can run into some problems of not running smoothly.\n\nfrom fastbook import *\n\n\nurls = search_images_ddg('bird photos', max_images = 1)\nlen(urls), urls[0]\n\n(1,\n 'http://www.zastavki.com/pictures/originals/2015/Animals___Birds_Flying_colorful_bird_093472_.jpg')\n\n\nHere we are searching in DuckDuckGo for images of birds and their URLs and stored in the variable urls.\nThe number of URLs and the URL of the first image is outputted.\n\ndest = Path('bird.jpg')\nif not dest.exists(): download_url(urls[0], dest, show_progress = False)\n\n\nim = Image.open(dest)\nim.to_thumb(256, 256)\n\n\n\n\nWe download the image, the first one.\nSo, the above script is something that can download images of birds (or anything for that matter) from the internet.\nOur goal is to build a system that can recognize images that are birds or not birds. Computers or models need numbers as inputs to work with. Luckily images are indeed made of numbers. PixSpy is an online viewer which helps us see these numbers in an image.\nExplanation of how images are stored‚Ä¶?\n\nsearches = 'forest', 'bird'\npath = Path('bird_or_not')\n\nif not path.exists():\n    for o in searches:\n        dest = path/o\n        dest.mkdir(exist_ok = True)\n        results = search_images_ddg(f'{o} photo')\n        download_images(dest, urls = results[:200])\n        resize_images(dest, max_size = 400, dest = dest)\n\nTo train our model, we need images of birds and non-birds, but DuckDuckGo or Google doesn‚Äôt show images of non-birds. So, we went with something like images of forests.\nIn the searches, we went and searched for forest images and bird images, and then downloaded and resized them, about 200 of them each.\nWe are resizing it to small pixels because computers take a large amount of time to just open an image that is larger in size.\n\nfailed = verify_images(get_image_files(path))\nfailed.map(Path.unlink);\n\nWhen we download images we often get a few broken ones(?)\nA model does not work successfully with broken images.\nThe above piece of code finds these broken images and unlinks them.\n{python} dls = DataBlock( blocks=(ImageBlock, CategoryBlock), get_items=get_image_files, splitter=RandomSplitter(valid_pct=0.2, seed=42), get_y=parent_label, item_tfms=[Resize(192, method=‚Äòsquish‚Äô)] ).dataloaders(path, bs=32) dls.show_batch(max_n=6)\n{python} dls = DataBlock( blocks = (ImageBlock, CategoryBlock), get_items = get_image_files, splitter = RandomSplitter(valid_pct = 0.2, seed = 42), get_y = parent_label, item_tfms = [Resize(192, method = ‚Äòsquish‚Äô)] ).dataloaders(path)\ndls.show_batch(max_n = 6)\nNow, we create what is called a data block.\nData block gives fast.ai library all the information of an image that it needs to create a computer vision model. It gets all the image files that we downloaded and shows us some, let us say 6. We can easily check the data with this.\nSo now we have downloaded 200 images of birds and forests each and have checked them.\n{python} learn = cnn_learner(dls, resnet18, metrics = error_rate) learn.fine_tune(3)\nHere, the model learns it. This now runs through every photo 400 and learns about how a bird or a forest looks like.\nOverall it took under 30 s which was enough to finish doing what we saw in the comic.\n{python} is_bird, _, probs = learn.predict(PILImage.create(‚Äòbird.jpg‚Äô)) print(f‚ÄùThis is a: {is_bird}.‚Äù) print(f‚ÄùProbability it‚Äôs a bird: {probs[0]:.4f}‚Äú)\nBy passing in our own image, we can check if an image is a bird or not with the probability rounded to the nearest to 4 decimal places.\nHence, something extraordinary has happened since 2015, something which was considered nearly impossible. What was once a joke, can now be done on our laptop in under 2 minutes."
  },
  {
    "objectID": "lesson1.html#key-takeaway-from-the-model-we-ran",
    "href": "lesson1.html#key-takeaway-from-the-model-we-ran",
    "title": "Lesson 1",
    "section": "Key Takeaway From The Model We Ran",
    "text": "Key Takeaway From The Model We Ran\nClearly, creating real-world deep learning working codes does not require:\n\nMuch Code\nMuch Math\nMuch Time\nMuch Data\nExpensive Computers\n\nHence, doing DL is pretty much accessible to everyone."
  },
  {
    "objectID": "lesson1.html#deep-learning-the-current-world-around-us",
    "href": "lesson1.html#deep-learning-the-current-world-around-us",
    "title": "Lesson 1",
    "section": "Deep Learning & The Current World Around Us",
    "text": "Deep Learning & The Current World Around Us\nDL is evolving rapidly, thereby giving rise to various new stuff. Following are some recent developments that came about a few weeks before the start of this course.\n\nDeep Learning & Art\n\nDALL.E 2, is an AI that can create real artistic images based on the descriptions we give it.  \nMidjourney, is another similar platform. \nSelf motivated artists use DL to create their own art working on a project for months. \n\nMany fast.ai alums having a background in art have went on to create wonderful arts using DL.\n\n\nDeep Learing & Language\n\nPathways Language Model (PaLM) from Google can take an English question as an input and return its output an answer with the explanation or ‚Äúthinking‚Äù. The diversity is vast ranging from Math problems to explaining jokes and beyond. \n\nIn short, DL is doing a lot that we would have considered impossible otherwise."
  },
  {
    "objectID": "lesson1.html#importance-of-ethics",
    "href": "lesson1.html#importance-of-ethics",
    "title": "Lesson 1",
    "section": "Importance Of Ethics",
    "text": "Importance Of Ethics\nAn important aspect to keep in consideration when venturing into solving and doing these cool things is Ethics. This will be touched upon in the course, but there is a full ethics course called Practical Data Ethics taught by Dr.¬†Rachel Thomas that covers things in detail."
  },
  {
    "objectID": "lesson1.html#jeremys-explorations-in-education",
    "href": "lesson1.html#jeremys-explorations-in-education",
    "title": "Lesson 1",
    "section": "Jeremy‚Äôs Explorations In Education",
    "text": "Jeremy‚Äôs Explorations In Education\nApart from being an AI Researcher, Jeremy is a homeschooling primary school teacher. This has led him to study education and bring the best education practices into his classrooms."
  },
  {
    "objectID": "lesson1.html#coloured-cups",
    "href": "lesson1.html#coloured-cups",
    "title": "Lesson 1",
    "section": "Coloured Cups",
    "text": "Coloured Cups\nOne of these practices is the Coloured Cups practice taken from an educator Dylan Wiliam which is an effective way for a teacher to get an idea of the classroom‚Äôs understanding of the lesson or a topic as it is being taught.\nThe idea is simple! All the students in the classrooms have 3 cups, a green cup, a yellow cup, and a red cup each reflecting various levels of understanding. Green means the student is understanding well, yellow means s/he is not quite sure what is going on, and red means the student has no idea of what is going on. As the lesson is being taught, the students put a cup on their desks and the teacher can see the classroom to get a sense of how the students are following along.\nFor this course, a virtual setup was made and Jeremy could see it from his end on the teacher version.\nThe above site was made by Radek one evening, one of the top Fast.ai alums and TA for the course.\n\n\n\nFigure 3: fast.ai version of the ‚ÄúColored Cups‚Äù\n\n\n\nTakeaway\nAs a learner, it is quite helpful to be self-aware of our situation. Hence, when taking the course independently, we can constantly ask ourselves how we are on the level of understanding.\nWhen we are at red the level, it is better to approach the forums and ask questions."
  },
  {
    "objectID": "lesson1.html#a-very-different-approach-to-doing-fast.ai",
    "href": "lesson1.html#a-very-different-approach-to-doing-fast.ai",
    "title": "Lesson 1",
    "section": "A Very Different Approach To Doing fast.ai",
    "text": "A Very Different Approach To Doing fast.ai\nWe began this course, by jumping right in by running a model. We did not do an in-depth review of Linear Algebra and Calculus.\nThis way of teaching is influenced by Jeremy‚Äôs two of the favourite educators Dylan Wiliam and Paul Lockhart (and many others), who claim that learning with a context at hand makes it much better for the learner to learn.\nThe way we learn math at school in a very dull way is first we learn counting, then adding, then decimals, blah blah blah and 15 years later in grad-school we do the actual cool stuff. This is not the way most people learn effectively.\nThe best way to learn is the way we learn sports. We jump right in on the ground and start playing it instead of sitting in a classroom and studying the physics of the sport.\nDo not worry though, we will go in-depth as we progress as the most sophisticated technically detailed class out there. but first, we focus on building and deploying models. we will learn why and how things work later.\nFolks having a technical background might find it difficult to cope with this style.\nThere will be a lot of tricks and cool learning philosophies that will be embedded and scattered throughout this course, sometimes it will be called out by Jeremy sometimes it won‚Äôt but it will be there."
  },
  {
    "objectID": "lesson1.html#the-book",
    "href": "lesson1.html#the-book",
    "title": "Lesson 1",
    "section": "The Book",
    "text": "The Book\nThe course is closely based on the textbook written by Jeremy and Sylvain titled Deep Learning for Coders with fastai and PyTorch: AI Applications Without a PhD.\nThe course will not use any materials from the book directly which might come as a surprise as we read, but the reason is that important educational research literature claims that learners learn best when the same thing is expressed in multiple different ways. The book will have the same information presented in a different way.\nOne of the bits of the HW is to read the corresponding chapter of the book.\nA lot of people love the book\n\n\n\nFigure : fast.ai textbook"
  },
  {
    "objectID": "lesson1.html#about-jeremy",
    "href": "lesson1.html#about-jeremy",
    "title": "Lesson 1",
    "section": "About Jeremy",
    "text": "About Jeremy\nSpent 30 years of his life working around DL & ML.\nHe built multiple companies centered around DL.\nHe is the highest-ranked competitor on Kaggle.\n\n\n\nFigure : About Jeremy\n\n\nOne of his companies Enlitic was the first company to specialize in DL for medicine.\nIt made it to the top 20 smartest companies in 2016 by MIT Technology Review.\n\n\n\nFigure : Enlitic featured in MIT Tech Review\n\n\nHe started fast.ai along with Rachel Thomas a few years ago and it had a big impact in the world already.\n\n\n\nFigure : fastai media coverage\n\n\nApart from the company‚Äôs success, along with the students they have had global recognitions for multiple projects and competitions.\nOne of them is their win in the DAWNBench competition, in which they demonstrated how they can train big neural networks, faster and cheaper than anybody in the world. That was a very big step in 2018.\n\n\n\nFigure : fastai vs Google\n\n\nSooner the work made a big difference. Google and NVIDIA started using their approaches and methods to optimise many of their projects.\n\n\n\nFigure : fastai used at NVIDIA\n\n\nHe is the inventor of the ULMFIT algorithm, which according to the  was one of the two key foundations behind the modern NLP revolution.\nInterestingly, the ULMFIT model did not appear in the journal first, but in the 2016 fast.ai course in lesson 4 and was later developed into a paper.\n\n\n\nFigure : Jeremy featured in an NLP textbook\n\n\nSince, the first year of teaching the course it got noticed by HBR\n\n\n\nFigure : Jeremy featured in an NLP textbook\n\n\nAnd the course is loved by most of them on YouTube.\n\n\n\nFigure : Lecture YouTube analytics\n\n\nMany alumni went on to do great things."
  },
  {
    "objectID": "lesson1.html#importance-of-the-course-in-the-industry",
    "href": "lesson1.html#importance-of-the-course-in-the-industry",
    "title": "Lesson 1",
    "section": "Importance Of The Course In The Industry",
    "text": "Importance Of The Course In The Industry\nThe course is widely used in industry and research with a lot of success.\nAndrej Karpathy said that everybody who joins the Tesla AI team are required to do this course.\nIn OpenAI all the residents joining are required to do this course."
  },
  {
    "objectID": "lesson1.html#comparison-between-learning-models-now-vs-back-then",
    "href": "lesson1.html#comparison-between-learning-models-now-vs-back-then",
    "title": "Lesson 1",
    "section": "Comparison Between Learning Models Now VS Back Then",
    "text": "Comparison Between Learning Models Now VS Back Then\nA surprising question to ask is how was our model able to tell if an image is of a bird or not. Why wasn‚Äôt it able to do earlier?\nLet us explore how image recognition was done in 2012, but before that, it is important to understand a few important terms.\n\nPathology\nA field or a branch of medicine, that deals with studying human tissue for the diagnosis of diseases.\nPathologists basically take samples of the human specimen and study it under microscopes to diagnose some disease, be it cancer, etc.\n\n\nComputational Pathology:\nUsing computer techniques in the process of pathology, i.e., using coding/ML/DL in order to study human tissues and predict the diagnosis of a disease.\n\n\nH&E Images\nWhen a pathologist studies a cell under a microscope, it is easier for him/her to see it clearly, when the cell is stained with some dye.\nA dye is a substance that gives colour to the substrate (to which it is applied to), for distinguishing purposes without chemically bonding with the substrate. Pigments on the other hand chemically bond with the substrate changing its molecular structure.\nIn medicine, the staining is done mostly by two dyes- hematoxylin and eosin.\nHematoxylin shows the ribosomes, chromatin (genetic material) within the nucleus, and other structures in a deep blue-purple colour.\nEosin shows the cytoplasm, collagen, connective tissue, and other structures that surround and support the cell as an orange-pink-red colour.\nHence, staining with hematoxylin and eosin (referred to as H & E staining) helps identify different types of cells and tissues and provides important information about the pattern, shape, and structure of cells in a tissue sample. It is used to help diagnose diseases, such as cancer.\nThe images or samples collected after the staining are called H&E images.\nTo summarize H & E images are images of various cells which are stained with two dyes- hematoxylin and eosin, in order to study them for diagnosis of a disease.\nNow let us get started.\n\n\nThe Story\n\n\n\nFigure : ML back then\n\n\nIn 2012, at Stanford, a diverse team of computational pathologists did a very successful and very famous project, which was exploring the 5-year survival chances of a cancer patient by looking at their histopathology slides.\nWhat they did back then was a classic Machine Learning approach.\nJeremy spoke to the senior author of the project, Daphne Koller, and asked why they didn‚Äôt use Deep Learning. Apparently, at that time DL wasn‚Äôt on the radar. Hence, this was a pre-deep learning approach.\nOne visible answer to how we are able to create a model for a bird recognizer is because of deep learning. The question then is, What is it exactly that is happening with DL, which could not happen with ML back then? Let us see!\nSo the way they did this, was gathered around a group of experts from multi-disciplinary fields ranging from Mathematicians to Computer Scientists, to Pathologists, and so on, and worked on building and creating this idea for ‚Äúfeatures‚Äù, features they did not even know of to include in their approach for image recognition.\nThere were thousands and thousands of these features. It took a lot of years, a lot of people, a lot of code, and a lot of math.\nOnce they got sufficient features they fed it to an ML model, a logistic regression model in this case.\nComing back to the question earlier, the difference between ML & DL is that DL uses NNs, and NNs don‚Äôt require humans to define any features for it. NNs develop the features themselves as it learns. That was the big difference."
  },
  {
    "objectID": "lesson1.html#how-dl-learns-features",
    "href": "lesson1.html#how-dl-learns-features",
    "title": "Lesson 1",
    "section": "How DL Learns Features?",
    "text": "How DL Learns Features?\nIn 2015, Matt Zeiler and Rob Fergus took a trained NN and looked inside it to see what it had learned about the features.\nBut wait?! What do we mean by looking inside a NN? It means looking at the weights.\nSo they looked at the weights inside and drew a picture of them. The following image shows the 9 sets of weights they found each representing a pattern in an image.\n\n\n\nFigure : Layer 1\n\n\nDeep Learning is deep because it takes the previous features and combines it with other features to create and detect more advanced features.\n\n\n\nFigure : Layer 2\n\n\nSo in neural networks we do not have to hard code these features, but just feed it examples and it will itself learn and recognize it.\n\n\n\nFigure : Layer 3\n\n\n\n\n\nFigure : Layer 1\n\n\nThe deeper the NN gets, it finds and detects more deeper features.\nEach of these feature detectors helps NN in understanding an image.\nClearly, trying to hard code would be very difficult.\nWe shall learn ahead how NNs learn this.\nThis is the key difference as said."
  },
  {
    "objectID": "lesson1.html#image-based-algorithms-go-beyond-images",
    "href": "lesson1.html#image-based-algorithms-go-beyond-images",
    "title": "Lesson 1",
    "section": "Image Based Algorithms Go Beyond Images",
    "text": "Image Based Algorithms Go Beyond Images\nA general theme can be set up for image based algorithms. But with creativity an image based recognizer can do thing beyond an image. For example:\n\nClassifying Sounds: A sound can be converted into a waveform which is an image and the model can be run on it to classify sounds with state of the art results. \nTime series: One of the students on the forum took a time series and converted it into a picture and used it in the image classifier. \nMotion-Movements: Another student created pictures of mouse-movements from users of a computer. The clicks became dots, the movements became lines, and the speed of the movement was captured in colour. \n\nHence, with creativity, anything non-image type if it can be converted into an image representation can be used in the image classifier model."
  },
  {
    "objectID": "lesson1.html#myths-around-doing-deep-learning",
    "href": "lesson1.html#myths-around-doing-deep-learning",
    "title": "Lesson 1",
    "section": "Myths Around Doing Deep Learning",
    "text": "Myths Around Doing Deep Learning\nAs we saw, when we trained a real working bird classifier, we:\n\nDidn‚Äôt use any Math\nDidn‚Äôt use much data (just 400 images)\nDidn‚Äôt use expensive computers\n\nThis is generally the case for the vast majority of doing DL in real life.\nThere will be some Math that will pop up which will be taught as needed or will be referred to external resources.\nThe Myths are passed along by big companies to store lots of data\nMost extraordinary real world projects don‚Äôt need expensive computers or vast data.\nThere are many platforms on which one can do state of the art DL for free.\nOne of the key reasons for this is Transfer Learning, which shall come ahead. Most people do not know about TL.\n\n\n\nFigure : Common myths"
  },
  {
    "objectID": "lesson1.html#pytorch-vs-tensorflow",
    "href": "lesson1.html#pytorch-vs-tensorflow",
    "title": "Lesson 1",
    "section": "PyTorch VS TensorFlow",
    "text": "PyTorch VS TensorFlow\nn this course, we will be using PyTorch.\nFolks who are way from the actual DL world would have heard of TensorFlow.\nTF is dying of its popularity in recent years, whereas PyTorch is growing rapidly.\nIn research repositories among the top papers, TF is a tiny minority compared to PyTorch.\nGreat research has come out of Ryan O‚ÄôConnor who also discovered that the majority of researchers using Tf in 2018 have shifted to PyTorch.\nWhat people use in research is a very strong leading indicator of what is going to happen in the industry because it is in research all new papers and algorithms are written about. Once a new paper of high impact factor comes it will bring changes in the research community and it is always better to adapt accordingly. Usually, industry takes some time to adopt these changes, but it will happen soon.\nPyTorch was used very early on when it was released for this course because based on the technical fundamentals it was clear that it was far better.\nHence, PyTorch will be used for this course.\n\n\n\nFigure : PyTorch vs TF"
  },
  {
    "objectID": "lesson1.html#pytorch-has-hairy-code",
    "href": "lesson1.html#pytorch-has-hairy-code",
    "title": "Lesson 1",
    "section": "PyTorch Has Hairy Code",
    "text": "PyTorch Has Hairy Code\nPyTorch has lengthy codes for relatively simple things.\nFollowing is a code for implementing and optimizer called Adam Optimizer in plain PyTorch taken from the PyTorch repository.\n\n\n\nFigure : An example of hairy code in PyTorch\n\n\nThe grey bit below does the exact same thing using the fast.ai library.\n\n\n\nFigure : fast.ai is better\n\n\nfast.ai is a library built by Jeremy and others on top of PyTorch.\nThis huge difference does not indicate that PyTorch is bad, but it reflects the strong foundations on which PyTorch is designed which can be used to build things on top of it, like fast.ai\nWhen we use the fast.ai library, we get access to all the power of PyTorch as well, but we shouldn‚Äôt be writing the former code when we can write the latter.\nThe problem with writing lots of code is there will be lots of things we can mistakes in, lots of things to not have best practices, lot of things to maintain\nIn general it is found that with DL less code is better.\nParticularly, with fast.ai, the code we don‚Äôt write is the code with the practices involved. Hence, using the codes, fast.ai provides, we will get better results.\nfast.ai library is very popular and is widely used in industry, academia, and teaching.\nAs we go with the course we will be seeing pure PyTorch as we go deeper and deeper to see how things work.\nIt won the 2020 best paper award and and hence is well regarded\n\n\n\nFigure : fast.ai best paper award"
  },
  {
    "objectID": "lesson1.html#jupyter-notebook",
    "href": "lesson1.html#jupyter-notebook",
    "title": "Lesson 1",
    "section": "Jupyter Notebook",
    "text": "Jupyter Notebook\nThe way Jeremy was able to run code snippets as slides was becuase of JNs.\nThis will be the environment in which we will be doing most of our computing for the course.\nIts a web based application which is popeular and widely used in industry academia and teaching.\nIts a powerful way to experiment explore and build.\nNow adays most people and students run JN not on the computer but on a cloud server.\nOn coursefastai we can see how to use.\nOne of the examples is on kaggle, which not only has competitions but also a cloud notebook server.\nwhen starting with our, just edit\nWhen starting with somones elses nb, it will show copy and edit.\nupvote before using to encourage folks\nthe first time we do this it sas session starting meaning its launching,\nwordls most powerful calculator, where we have all the capabilities of all the programming language at our disposal\ni hate clicking use keyboard shortcuts\nmarkdown pros\n! means bash shell command\nimages"
  },
  {
    "objectID": "resources.html",
    "href": "resources.html",
    "title": "Resources",
    "section": "",
    "text": "Here I curate relevant materials which I use for regular reference."
  },
  {
    "objectID": "movies.html",
    "href": "movies.html",
    "title": "Samar Zayan",
    "section": "",
    "text": "Movies"
  },
  {
    "objectID": "chapter1.html",
    "href": "chapter1.html",
    "title": "Samar Zayan",
    "section": "",
    "text": "chap 1"
  }
]